{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9c7650",
   "metadata": {},
   "source": [
    "Environment Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38859493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:51:45.714143Z",
     "start_time": "2024-06-06T00:51:45.701266Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from sas7bdat import SAS7BDAT\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "from typing import List, Union, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2331a",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046d12ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:52:27.036824Z",
     "start_time": "2024-06-06T00:51:45.717707Z"
    }
   },
   "outputs": [],
   "source": [
    "acs_raw_person  = pd.read_csv(\"Data/ACS_5YR/2018_2022/csv_pca/psam_p06.csv\")\n",
    "acs_raw_housing = pd.read_csv('Data/ACS_5YR/2018_2022/csv_hca/psam_h06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c9da89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:53:08.736486Z",
     "start_time": "2024-06-06T00:52:27.038638Z"
    }
   },
   "outputs": [],
   "source": [
    "acs_raw = pd.merge(acs_raw_person, acs_raw_housing, on='SERIALNO', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebeceb64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:53:53.586360Z",
     "start_time": "2024-06-06T00:53:08.738569Z"
    }
   },
   "outputs": [],
   "source": [
    "with SAS7BDAT('Data/CHIS Dummy/Adult 2022/dummy_adult.sas7bdat') as file:\n",
    "    chis_raw = file.to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bb31d",
   "metadata": {},
   "source": [
    "Data Manipulation Toolbox - DataToolBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6977877a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:53:53.613621Z",
     "start_time": "2024-06-06T00:53:53.588471Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataToolBox:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the DataToolBox with a dataset.\n",
    "\n",
    "        :param data: A pandas DataFrame that contains the data to be analyzed and manipulated.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def return_data(self):\n",
    "        \"\"\"\n",
    "        Return the current state of the data stored in the toolbox.\n",
    "\n",
    "        :return: The current pandas DataFrame stored within the tool.\n",
    "        \"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def data_desc(self):\n",
    "        \"\"\"\n",
    "        Print a description of the current dataset including the number of observations (rows) and variables (columns).\n",
    "        \"\"\"\n",
    "        temp = self.data.shape\n",
    "        print(\"---------Current Data State----------\")\n",
    "        print(temp[0], \"obs;\", temp[1], \"vars\")\n",
    "        print(\"\")\n",
    "\n",
    "    def data_exclude(self, condition: str):\n",
    "        \"\"\"\n",
    "        Exclude observations from the data based on a given condition and updates the dataset.\n",
    "\n",
    "        :param condition: A string representing the condition to be used for filtering the data.\n",
    "                          Observations meeting this condition will be excluded.\n",
    "        \"\"\"\n",
    "        temp = self.data.query(condition)\n",
    "        temp_new_obs = temp.shape[0]\n",
    "        temp_old_obs = self.data.shape[0]\n",
    "        temp_diff_obs = temp_old_obs - temp_new_obs\n",
    "\n",
    "        print(\"---------Obs Filter-----------------\")\n",
    "        print(\"applying condition: \", condition)\n",
    "        print(temp_diff_obs, \"/\", temp_old_obs, \"cases were removed\")\n",
    "        print(\"new obs #: \", temp_new_obs)\n",
    "        print(\"\")\n",
    "\n",
    "        self.data = temp\n",
    "\n",
    "#     def freq_1way(self, col_name):\n",
    "#         \"\"\"\n",
    "#         Print the frequency count and percentage distribution of a single column, sorted by index,\n",
    "#         and display it in a formatted table with borders. Rows with a count of zero are not shown.\n",
    "\n",
    "#         :param col_name: The name of the column for which the frequency distribution is to be calculated.\n",
    "#         \"\"\"\n",
    "#         # Get counts and sort by index\n",
    "#         counts = self.data[col_name].value_counts(dropna=False).sort_index()\n",
    "#         # Calculate percentages\n",
    "#         percentages = (counts / counts.sum()) * 100\n",
    "#         # Combine counts and percentages into a single DataFrame for better display\n",
    "#         frequency_df = pd.DataFrame({\n",
    "#             'Counts': counts,\n",
    "#             'Percentage': percentages\n",
    "#         })\n",
    "\n",
    "#         # Filter out rows with zero counts and reset the index\n",
    "#         frequency_df = frequency_df[frequency_df['Counts'] > 0].reset_index()\n",
    "\n",
    "#         # Print results using tabulate for better formatting\n",
    "#         print(\"---------Frequency Distribution for\", col_name, \"----------\")\n",
    "#         print(\n",
    "#             tabulate(frequency_df,\n",
    "#                      headers='keys',\n",
    "#                      tablefmt='grid',\n",
    "#                      showindex=False))\n",
    "#         print(\"\")\n",
    "    def freq_1way(self, col_name, weight_col=None, include_unweighted=False):\n",
    "        \"\"\"\n",
    "        Print the frequency count and percentage distribution of a single column, sorted by index,\n",
    "        and display it in a formatted table with borders. Rows with a count of zero are not shown.\n",
    "        If a weight column is specified, it calculates weighted frequency and percentages.\n",
    "\n",
    "        :param col_name: The name of the column for which the frequency distribution is to be calculated.\n",
    "        :param weight_col: Optional. The name of the column to be used for weighting the frequency and percentages.\n",
    "        :param include_unweighted: Optional. Whether to include unweighted results alongside weighted results.\n",
    "        \"\"\"\n",
    "        if weight_col:\n",
    "            if weight_col not in self.data.columns:\n",
    "                print(f\"Error: The weight column '{weight_col}' does not exist.\")\n",
    "                return\n",
    "\n",
    "            # Weighted frequency and percentage\n",
    "            weighted_counts = self.data.groupby(col_name)[weight_col].sum()\n",
    "            weighted_percentages = (weighted_counts / weighted_counts.sum()) * 100\n",
    "            weighted_df = pd.DataFrame({\n",
    "                'Weighted Counts': weighted_counts,\n",
    "                'Weighted Percentage': weighted_percentages\n",
    "            })\n",
    "\n",
    "            # Unweighted frequency and percentage\n",
    "            if include_unweighted:\n",
    "                counts = self.data[col_name].value_counts(dropna=False).sort_index()\n",
    "                percentages = (counts / counts.sum()) * 100\n",
    "                unweighted_df = pd.DataFrame({\n",
    "                    'Unweighted Counts': counts,\n",
    "                    'Unweighted Percentage': percentages\n",
    "                })\n",
    "                frequency_df = pd.concat([unweighted_df, weighted_df], axis=1)\n",
    "                title = f\"Frequency Distribution for {col_name} (Weighted and Unweighted)\"\n",
    "            else:\n",
    "                frequency_df = weighted_df\n",
    "                title = f\"Frequency Distribution for {col_name} (Weighted)\"\n",
    "        else:\n",
    "            # Unweighted frequency and percentage\n",
    "            counts = self.data[col_name].value_counts(dropna=False).sort_index()\n",
    "            percentages = (counts / counts.sum()) * 100\n",
    "            frequency_df = pd.DataFrame({\n",
    "                'Counts': counts,\n",
    "                'Percentage': percentages\n",
    "            })\n",
    "            title = f\"Frequency Distribution for {col_name} (Unweighted)\"\n",
    "\n",
    "        # Filter out rows with zero counts and reset the index\n",
    "        frequency_df = frequency_df[(frequency_df > 0).any(axis=1)].reset_index()\n",
    "        pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "        # Print results using tabulate for better formatting\n",
    "        print(\"---------\", title, \"----------\")\n",
    "        print(\n",
    "            tabulate(frequency_df,\n",
    "                     headers='keys',\n",
    "                     tablefmt='grid',\n",
    "                     showindex=False))\n",
    "        print(\"\")\n",
    "        pd.reset_option('display.float_format')\n",
    "\n",
    "    def freq_2way(self, col_name_1, col_name_2, exclude_equal=False):\n",
    "        # Fill NaN values with a placeholder (e.g., 'Missing') for visibility in crosstab\n",
    "        # Make a copy to avoid changing the original data\n",
    "        temp_data = self.data\n",
    "        temp_data[col_name_1] = temp_data[col_name_1].fillna('NaN')\n",
    "        temp_data[col_name_2] = temp_data[col_name_2].fillna('NaN')\n",
    "\n",
    "        # Generate crosstab data\n",
    "        crosstab_result = pd.crosstab(temp_data[col_name_1],\n",
    "                                      temp_data[col_name_2],\n",
    "                                      rownames=[col_name_1],\n",
    "                                      colnames=[col_name_2])\n",
    "\n",
    "        # Reset index to make crosstab a regular DataFrame\n",
    "        crosstab_result = crosstab_result.reset_index()\n",
    "\n",
    "        # Melt the DataFrame to get a long format\n",
    "        melted_crosstab = crosstab_result.melt(\n",
    "            id_vars=[col_name_1], value_name='COUNT')\n",
    "\n",
    "        # Filter out rows where COUNT is zero and optionally where values in column A are equal to values in column B\n",
    "        if exclude_equal:\n",
    "            melted_crosstab = melted_crosstab[\n",
    "                (melted_crosstab['COUNT'] > 0)\n",
    "                & (melted_crosstab[col_name_1] != melted_crosstab[col_name_2])]\n",
    "            title = f\"Two-way Frequency Table for {col_name_1} and {col_name_2} (Unequal Values Only)\"\n",
    "        else:\n",
    "            melted_crosstab = melted_crosstab[melted_crosstab['COUNT'] > 0]\n",
    "            title = f\"Two-way Frequency Table for {col_name_1} and {col_name_2}\"\n",
    "\n",
    "        # Print results using tabulate for better formatting\n",
    "        print(\"---------\", title, \"----------\")\n",
    "        print(\n",
    "            tabulate(melted_crosstab,\n",
    "                     headers='keys',\n",
    "                     tablefmt='grid',\n",
    "                     showindex=False))\n",
    "        print(\"\")\n",
    "\n",
    "    def freq_multiway(self, columns, exclude_zeros=True, exclude_equal=False):\n",
    "        # Make a copy to avoid changing the original data\n",
    "        temp_data = self.data\n",
    "\n",
    "        # Replace NaN values with a placeholder to ensure they are included as a category\n",
    "        for col in columns:\n",
    "            temp_data[col] = temp_data[col].fillna('NaN')\n",
    "\n",
    "        # Generate crosstab data\n",
    "        crosstab_result = pd.crosstab(\n",
    "            index=[temp_data[col] for col in columns[:-1]],\n",
    "            columns=temp_data[columns[-1]],\n",
    "            rownames=columns[:-1],\n",
    "            colnames=[columns[-1]])\n",
    "\n",
    "        # Reset index to make crosstab a regular DataFrame and flatten MultiIndex\n",
    "        crosstab_result.reset_index(inplace=True)\n",
    "        melted_crosstab = pd.melt(\n",
    "            crosstab_result, id_vars=columns[:-1], value_name='COUNT')\n",
    "\n",
    "        # Apply filters\n",
    "        if exclude_zeros:\n",
    "            melted_crosstab = melted_crosstab[melted_crosstab['COUNT'] > 0]\n",
    "\n",
    "        if exclude_equal and len(columns) > 1:\n",
    "            # Check if all elements in each row are equal\n",
    "            equal_filter = melted_crosstab.apply(lambda row: len(\n",
    "                set(row[columns[:-1]].tolist() + [row[columns[-1]]])) == 1,\n",
    "                axis=1)\n",
    "            melted_crosstab = melted_crosstab[~equal_filter]\n",
    "\n",
    "        # Sort the results\n",
    "        melted_crosstab.sort_values(by=columns, inplace=True)\n",
    "\n",
    "        # Print results using tabulate for better formatting\n",
    "        title = f\"Multi-way Frequency Table for {' ,'.join(columns)}\"\n",
    "        if exclude_equal:\n",
    "            title += \" (Non-equal Values Only)\"\n",
    "        print(\"---------\", title, \"----------\")\n",
    "        print(\n",
    "            tabulate(melted_crosstab,\n",
    "                     headers='keys',\n",
    "                     tablefmt='grid',\n",
    "                     showindex=False))\n",
    "        print(\"\")\n",
    "\n",
    "    def data_construct(self, col_name, conditions_str, choices, default=-1):\n",
    "        \"\"\"\n",
    "        Construct a new column in the data based on multiple conditions,\n",
    "        where choices can be either fixed values or column references.\n",
    "        Stop checking further conditions once a true condition is met for a row.\n",
    "\n",
    "        :param col_name: Name of the new column to be added.\n",
    "        :param conditions_str: A list of conditions (as strings) that determine the value to be assigned.\n",
    "        :param choices: A list of values or column names to be assigned based on the conditions.\n",
    "        :param default: The default value or column name to be assigned if none of the conditions are met. Default is -1.\n",
    "        \"\"\"\n",
    "        temp_df = self.data\n",
    "\n",
    "        # Initialize the new column with NaNs which will be replaced by the default at the end\n",
    "        temp_df[col_name] = np.nan\n",
    "\n",
    "        # Loop through each condition and choice, assign only if the column is still NaN\n",
    "        for condition, choice in zip(conditions_str, choices):\n",
    "            condition_series = temp_df.eval(condition)\n",
    "            if isinstance(choice, str) and choice in temp_df.columns:\n",
    "                # Apply choice from another column\n",
    "                temp_df.loc[condition_series & temp_df[col_name].isna(),\n",
    "                            col_name] = temp_df.loc[condition_series, choice]\n",
    "            else:\n",
    "                # Apply fixed choice\n",
    "                temp_df.loc[condition_series & temp_df[col_name].isna(),\n",
    "                            col_name] = choice\n",
    "\n",
    "        # Fill remaining NaNs with the default value\n",
    "        if isinstance(default, str) and default in temp_df.columns:\n",
    "            temp_df[col_name].fillna(temp_df[default], inplace=True)\n",
    "        else:\n",
    "            temp_df[col_name].fillna(default, inplace=True)\n",
    "\n",
    "        self.data = temp_df\n",
    "\n",
    "    def copy_column(self, source_col, target_col):\n",
    "        \"\"\"\n",
    "        Copies the values from one column to another, preserving the original column.\n",
    "\n",
    "        :param source_col: The name of the source column whose values are to be copied.\n",
    "        :param target_col: The name of the target column to which the values will be copied.\n",
    "        \"\"\"\n",
    "        if source_col in self.data.columns:\n",
    "            self.data[target_col] = self.data[source_col]\n",
    "            print(\n",
    "                f\"Values from '{source_col}' were successfully copied to '{target_col}'.\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error: The column '{source_col}' does not exist in the DataFrame.\")\n",
    "    def fill_all_nans(self, fill_value):\n",
    "        \"\"\"\n",
    "        Replace NaN values across all columns of the DataFrame with a specified value.\n",
    "\n",
    "        :param fill_value: The value to use for replacing NaNs across all columns.\n",
    "        \"\"\"\n",
    "        # Replace NaN values in all columns with the specified fill value\n",
    "        self.data.fillna(fill_value, inplace=True)\n",
    "        print(f\"All NaN values have been replaced with {fill_value}.\")\n",
    "        \n",
    "    def select_columns(self, col_list=None, prefixes=None):\n",
    "        \"\"\"\n",
    "        Selects columns based on a list or common prefixes and updates the dataset.\n",
    "\n",
    "        :param col_list: A list of column names to be retained in the dataset.\n",
    "        :param prefixes: A list of common prefixes for column names to be retained. If both col_list and prefixes are provided,\n",
    "                         columns that either match the list or any of the prefixes are retained.\n",
    "        \"\"\"\n",
    "        cols_to_keep = set()\n",
    "\n",
    "        if col_list:\n",
    "            # Add columns from col_list to the set of columns to keep\n",
    "            cols_to_keep.update(col_list)\n",
    "\n",
    "        if prefixes:\n",
    "            # Add columns that start with any of the provided prefixes\n",
    "            for prefix in prefixes:\n",
    "                cols_to_keep.update(col for col in self.data.columns if col.startswith(prefix))\n",
    "\n",
    "        if not cols_to_keep:\n",
    "            # If neither col_list nor prefixes are provided, or no columns match, raise an error\n",
    "            raise ValueError(\"Either col_list or prefixes must be provided, and they must match existing columns.\")\n",
    "\n",
    "        # Filter the dataframe to only keep the selected columns\n",
    "        self.data = self.data[list(cols_to_keep)]\n",
    "        print(f\"Data now contains only the selected columns: {list(cols_to_keep)}\")\n",
    "        \n",
    "    def export_data(self, file_name, format, include_freq_report=False, max_categories=None, folder_path=None):\n",
    "        \"\"\"\n",
    "        Export the data to a specified format and optionally create a frequency report for each variable.\n",
    "\n",
    "        :param file_name: Name of the file without the extension.\n",
    "        :param format: Format of the file to save ('excel', 'csv', 'stata', 'r', 'spss', 'sql').\n",
    "        :param include_freq_report: Whether to include a frequency report as a separate file.\n",
    "        :param max_categories: Maximum number of categories to include in the frequency reports for each variable.\n",
    "        :param folder_path: The directory to save the file. If None, uses the current working directory.\n",
    "        \"\"\"\n",
    "        # Define the file extension based on the format\n",
    "        extensions = {\n",
    "            'excel': '.xlsx',\n",
    "            'csv': '.csv',\n",
    "            'stata': '.dta',\n",
    "            'r': '.pkl',  # Using pickle for R, though this is unconventional\n",
    "            'spss': '.sav',\n",
    "            'sql': ''  # SQL doesn't have a file extension for exporting; it interacts with databases\n",
    "        }\n",
    "\n",
    "        if format not in extensions:\n",
    "            raise ValueError(\"Unsupported file format specified.\")\n",
    "\n",
    "        if folder_path is None:\n",
    "            folder_path = os.getcwd()  # Use the current working directory if no folder path is provided\n",
    "\n",
    "        # Add a date suffix to the filename\n",
    "        date_suffix = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "        base_file_path = os.path.join(folder_path, f\"{file_name}_{date_suffix}\")\n",
    "\n",
    "        # Check if the file already exists and add a random number if it does\n",
    "        full_file_path = base_file_path + extensions[format]\n",
    "        while os.path.exists(full_file_path):\n",
    "            random_suffix = random.randint(1000, 9999)  # Generate a random four-digit number\n",
    "            full_file_path = f\"{base_file_path}_{random_suffix}\" + extensions[format]\n",
    "\n",
    "        # Export data to the chosen format\n",
    "        if format == 'excel':\n",
    "            self.data.to_excel(full_file_path, index=False)\n",
    "        elif format == 'csv':\n",
    "            self.data.to_csv(full_file_path, index=False)\n",
    "        elif format == 'stata':\n",
    "            self.data.to_stata(full_file_path)\n",
    "        elif format == 'r':\n",
    "            self.data.to_pickle(full_file_path)\n",
    "        elif format == 'spss':\n",
    "            import pyreadstat  # Requires 'pyreadstat' module for SPSS\n",
    "            pyreadstat.write_sav(self.data, full_file_path)\n",
    "        elif format == 'sql':\n",
    "            self.data.to_sql(name='table_name', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "        # Optionally generate a frequency report\n",
    "        if include_freq_report:\n",
    "            freq_full_path = full_file_path.replace(extensions[format], '_freq_report.xlsx')\n",
    "\n",
    "            with pd.ExcelWriter(freq_full_path) as writer:\n",
    "                for column in self.data.columns:\n",
    "                    freq_df = self.export_freq_1way(column, max_categories=max_categories)\n",
    "                    freq_df.to_excel(writer, sheet_name=column, index=False)\n",
    "\n",
    "            print(f\"Frequency report has been saved to {freq_full_path}\")\n",
    "\n",
    "    def export_freq_1way(self, col_name, max_categories=None):\n",
    "        \"\"\"\n",
    "        Generate a DataFrame of frequency counts and percentages for a column, with an optional limit on categories.\n",
    "        Specifically designed for exporting data.\n",
    "\n",
    "        :param col_name: Column name for frequency calculation.\n",
    "        :param max_categories: Maximum number of categories to include. If more categories are present, only the top categories by count are shown.\n",
    "        :return: DataFrame with frequency counts and percentages.\n",
    "        \"\"\"\n",
    "        counts = self.data[col_name].value_counts(dropna=False)\n",
    "        if max_categories is not None and len(counts) > max_categories:\n",
    "            counts = counts.nlargest(max_categories)\n",
    "        percentages = (counts / counts.sum()) * 100\n",
    "        frequency_df = pd.DataFrame({\n",
    "            'Counts': counts,\n",
    "            'Percentage': percentages\n",
    "        }).reset_index().rename(columns={'index': 'Category'})\n",
    "        return frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c104e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:54:12.271199Z",
     "start_time": "2024-06-06T00:53:53.614513Z"
    }
   },
   "outputs": [],
   "source": [
    "acs_working = acs_raw\n",
    "\n",
    "conditions = [\n",
    "    acs_raw['SERIALNO'].str[4:6] == 'GQ',  # Condition for 'GQ'\n",
    "    acs_raw['SERIALNO'].str[4:6] == 'HU'   # Condition for 'HU'\n",
    "]\n",
    "\n",
    "choices = [1, 0]\n",
    "\n",
    "acs_working['INGRPQ'] = np.select(conditions, choices, default = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9798a6c",
   "metadata": {},
   "source": [
    "ACS Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee783b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:54:31.781344Z",
     "start_time": "2024-06-06T00:54:12.273625Z"
    }
   },
   "outputs": [],
   "source": [
    "acs = DataToolBox(acs_working)\n",
    "acs.data_desc()\n",
    "acs.data_exclude('INGRPQ == 0')\n",
    "acs.data_exclude('AGEP >= 18')\n",
    "acs.fill_all_nans(-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c261b7a",
   "metadata": {},
   "source": [
    "CHIS Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a8661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:54:31.787470Z",
     "start_time": "2024-06-06T00:54:31.783322Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chis = DataToolBox(chis_raw)\n",
    "chis.data_desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67257de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:54:40.270842Z",
     "start_time": "2024-06-06T00:54:31.789291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acs.data_construct(\"sc_sex\", ['SEX == 1', \"SEX == 2\"], [1,2])\n",
    "chis.data_construct('sc_sex', [\"SRSEX == 1\", \"SRSEX == 2\"], [1,2])\n",
    "\n",
    "acs.freq_2way('SEX', \"sc_sex\")\n",
    "chis.freq_2way('SRSEX', \"sc_sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs.freq_1way('sc_sex', \"PWGTP\", include_unweighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087f7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:54:54.337901Z",
     "start_time": "2024-06-06T00:54:40.272809Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct(\"sc_age_cont\", ['AGEP <=99'], ['AGEP'])\n",
    "chis.data_construct('sc_age_cont', ['SRAGE < 99', 'SRAGE >= 99'], ['SRAGE', 99])\n",
    "\n",
    "acs.freq_2way('AGEP','sc_age_cont', exclude_equal=True)\n",
    "chis.freq_2way('SRAGE', 'sc_age_cont', exclude_equal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdd9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:08.554725Z",
     "start_time": "2024-06-06T00:54:54.339447Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_age_cat', [\n",
    "    'AGEP < 18', 'AGEP >= 18 & AGEP < 25', 'AGEP >= 25 & AGEP < 35',\n",
    "    'AGEP >= 35 & AGEP < 45', 'AGEP >= 45 & AGEP < 55',\n",
    "    'AGEP >= 55 & AGEP <= 64', 'AGEP >= 65'\n",
    "], list(range(7)))\n",
    "chis.data_construct('sc_age_cat', [\n",
    "    'SRAGE < 18', 'SRAGE >= 18 & SRAGE < 25', 'SRAGE >= 25 & SRAGE < 35',\n",
    "    'SRAGE >= 35 & SRAGE < 45', 'SRAGE >= 45 & SRAGE < 55',\n",
    "    'SRAGE >= 55 & SRAGE <= 64', 'SRAGE >= 65'\n",
    "], list(range(7)))\n",
    "acs.freq_2way('AGEP', 'sc_age_cat')\n",
    "chis.freq_2way('SRAGE', 'sc_age_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd9d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:22.423256Z",
     "start_time": "2024-06-06T00:55:08.556210Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_hisp', ['HISP == 1', 'HISP != 1'], [1, 2])\n",
    "acs.freq_2way('HISP', 'sc_hisp')\n",
    "\n",
    "chis.data_construct('sc_hisp', ['SRH == 1', 'SRH != 1'], [1, 2])\n",
    "chis.freq_2way('SRH', 'sc_hisp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95929025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:35.916936Z",
     "start_time": "2024-06-06T00:55:22.426527Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_race_ethi', [\n",
    "    'HISP == 1', 'RAC1P == 1', 'RAC1P == 2', 'RAC1P == 3 | RAC1P == 4 |RAC1P == 5',\n",
    "    'RAC1P == 6', 'RAC1P == 7', 'RAC1P == 8 | RAC1P == 9'\n",
    "], [1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "chis.copy_column('OMBSRREO','sc_race_ethi')\n",
    "\n",
    "acs.freq_multiway(['sc_hisp', 'RAC1P','sc_race_ethi'])\n",
    "chis.freq_2way('OMBSRREO', 'sc_race_ethi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a1d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:49.186498Z",
     "start_time": "2024-06-06T00:55:35.924364Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_cit', ['CIT == 1|CIT == 2|CIT==3', 'CIT ==4', 'CIT==5'],\n",
    "                   [1, 2, 3])\n",
    "chis.copy_column('CITIZEN2', \"sc_cit\")\n",
    "\n",
    "acs.freq_2way('CIT', 'sc_cit')\n",
    "chis.freq_2way('CITIZEN2', 'sc_cit')\n",
    "\n",
    "acs.freq_1way('sc_cit')\n",
    "chis.freq_1way('sc_cit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b32c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:49.542623Z",
     "start_time": "2024-06-06T00:55:49.188067Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_edu', [\n",
    "    'SCHL >= 4 & SCHL <= 11', 'SCHL >= 12 & SCHL <= 14',\n",
    "    'SCHL >= 15 & SCHL <= 17', 'SCHL >= 18 & SCHL <= 19', 'SCHL == 20',\n",
    "    'SCHL == 21', 'SCHL == 22', 'SCHL == 23', 'SCHL == 24',\n",
    "    'SCHL >= 1 & SCHL <= 3', 'SCHL == -9'\n",
    "], [1, 2, 3, 4, 6, 7, 9, 8, 10, 91, 91])\n",
    "\n",
    "chis.copy_column('AHEDUC', 'sc_edu')\n",
    "\n",
    "# acs.freq_2way(\"SCHL\", 'sc_edu')\n",
    "# chis.freq_2way(\"AHEDUC\", 'sc_edu')\n",
    "\n",
    "acs.freq_1way('sc_edu')\n",
    "chis.freq_1way('sc_edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229969a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:55:49.559546Z",
     "start_time": "2024-06-06T00:55:49.543529Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.copy_column('HICOV', \"sc_ins\")\n",
    "chis.copy_column('INS', \"sc_ins\")\n",
    "\n",
    "acs.freq_1way('sc_ins')\n",
    "chis.freq_1way('sc_ins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f569b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:03.599764Z",
     "start_time": "2024-06-06T00:55:49.561467Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_emp', ['ESR == 1|ESR ==4', 'ESR == 2|ESR ==5','ESR == 3|ESR ==6' ], [1,2, 3])\n",
    "chis.data_construct('sc_emp', ['WRKST == 1|WRKST == 2', 'WRKST == 3', 'WRKST == 4|WRKST == 5'], [1,2,3])\n",
    "\n",
    "\n",
    "acs.freq_2way('ESR', 'sc_emp')\n",
    "chis.freq_2way('WRKST', 'sc_emp')\n",
    "\n",
    "acs.freq_1way('sc_emp')\n",
    "chis.freq_1way('sc_emp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f45bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:03.687501Z",
     "start_time": "2024-06-06T00:56:03.601564Z"
    }
   },
   "outputs": [],
   "source": [
    "# acs.freq_1way('TEN')\n",
    "\n",
    "acs.data_construct('sc_housing', ['TEN == 1 | TEN == 2', 'TEN == 3 | TEN == 4'], [1,2])\n",
    "chis.copy_column('SRTENR', \"sc_housing\")\n",
    "# acs.freq_2way('TEN', \"sc_housing\")\n",
    "\n",
    "acs.freq_1way('sc_housing')\n",
    "chis.freq_1way('sc_housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bcec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:03.890832Z",
     "start_time": "2024-06-06T00:56:03.689782Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.data_construct('sc_poverty', ['POVPIP <= 99', 'POVPIP >= 100 & POVPIP <= 199',\n",
    "                   'POVPIP >= 200 & POVPIP <= 299', 'POVPIP >= 300'], [1, 2, 3, 4])\n",
    "chis.copy_column('POVLL', 'sc_poverty')\n",
    "\n",
    "acs.freq_1way('sc_poverty')\n",
    "chis.freq_1way('sc_poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2215720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:04.360671Z",
     "start_time": "2024-06-06T00:56:03.892401Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.copy_column('MAR', 'sc_marit')\n",
    "chis.data_construct('sc_marit', ['AH43 == 1', 'AH43 == 3', 'AH43 == 4',\n",
    "                    'AH43 == 5', 'AH43 == 2|AH43 == 6'], [1, 2, 3, 4, 5])\n",
    "\n",
    "chis.freq_2way('AH43', 'sc_marit')\n",
    "\n",
    "acs.freq_1way('sc_marit')\n",
    "chis.freq_1way('sc_marit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c2fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:13.333848Z",
     "start_time": "2024-06-06T00:56:04.361619Z"
    }
   },
   "outputs": [],
   "source": [
    "chis.select_columns(prefixes= ['sc_', 'RAKEDW'])\n",
    "acs.select_columns(prefixes=['sc', 'PWGTP', 'PUMA10', 'PUMA20', 'REGION', 'ST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a281c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:37.714219Z",
     "start_time": "2024-06-06T00:56:13.335486Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acs.export_data('acs', 'csv', include_freq_report=True, max_categories=20, folder_path='Data/Output Data')\n",
    "chis.export_data('chis', 'csv', include_freq_report=True, max_categories=20, folder_path='Data//Output Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e2058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T00:56:57.407165Z",
     "start_time": "2024-06-06T00:56:37.715160Z"
    }
   },
   "outputs": [],
   "source": [
    "acs.export_data('acs', 'stata', include_freq_report=True, max_categories=20, folder_path='Data/Output Data')\n",
    "chis.export_data('chis', 'stata', include_freq_report=True, max_categories=20, folder_path='Data//Output Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2a682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:02:12.287395Z",
     "start_time": "2024-06-06T01:02:12.276831Z"
    }
   },
   "outputs": [],
   "source": [
    "acs_model = acs.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050d55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:04:21.661487Z",
     "start_time": "2024-06-06T01:04:21.638807Z"
    }
   },
   "outputs": [],
   "source": [
    "import pysurveys as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9086d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:05:52.987772Z",
     "start_time": "2024-06-06T01:05:52.323958Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
